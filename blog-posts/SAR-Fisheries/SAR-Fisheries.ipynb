{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "Title: Extracting GFW's Fishing Effort Data using Earth Engine Python API\n",
        "format:\n",
        "  html:\n",
        "    theme:\n",
        "      - default\n",
        "      - custom.scss\n",
        "    code-fold: true\n",
        "    toc-title: 'Contents:'\n",
        "    toc: true\n",
        "    link-external-newwindow: true\n",
        "execute:\n",
        "  warning: false\n",
        "  message: false\n",
        "---"
      ],
      "id": "7441981e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import folium\n",
        "import ipywidgets\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from folium import plugins, FeatureGroup\n",
        "from folium.plugins import HeatMap, TimeSliderChoropleth\n",
        "from shapely.geometry import Polygon\n",
        "from branca.colormap import linear\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.graph_objs as go\n",
        "from sklearn import preprocessing"
      ],
      "id": "52a77ccb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vessel detection using Synthetic Aperture Radar: Potential for improved fisheries management\n",
        "\n",
        "In this post, we highlight the practical application of the vessel detection model described in the previous post, using Sentinel 1 SAR images from the ESA Copernicus program. We illustrate how the derived data can be used to monitor fishing activities, while also demonstrating the contributions of these technologies to fisheries management.\n",
        "\n",
        "## Transforming model outputs\n",
        "\n",
        "A total of 348 images, amounting to 93GB of data, were extracted from the Google Earth Engine (GEE) and processed to evaluate a period from January 2018 to December 2022, covering 1024011 km2. The detection model was applied after reprojecting the images to a CRS of interest. The resulting bounding boxes from the model were converted into coordinate points, representing the precise locations of the detected vessels. The images below provide visual examples of this process. Starting with the raw images, the vessels are detected using the model, and their bounding boxes are extracted. By calculating the centroids of these bounding boxes, we obtain the accurate coordinates of the vessels. This transformation of the model outputs into meaningful data has great potential for various applications, including fisheries management.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  [<img src=\"assets/raw_test_image.jpg\" alt=\"Raw Test Image\" width=\"30%\" height=\"30%\" />](assets/raw_test_image.jpg)\n",
        "  [<img src=\"assets/bounded_test_image.jpg\" alt=\"Bounded Test Image\" width=\"30%\" height=\"30%\" />](assets/bounded_test_image.jpg)\n",
        "  [<img src=\"assets/centroids_test_image.jpg\" alt=\"Centroids Test Image\" width=\"30%\" height=\"30%\" />](assets/centroids_test_image.jpg)\n",
        "</div>\n",
        "\n",
        "You can find the code necessary for image access, detection processing, and transforming the model outputs into meaningfull data in the following link:\n",
        "\n",
        "https://github.com/pcarbomestre/SAR-VesselDetection-FisheriesMonitoring/tree/main/case_study\n",
        "\n",
        "## Case Study\n",
        "\n",
        "The specific marine region under examination is the Corcovado Gulf, located in southern Chile. We chose this area as a case study based on three criteria. Firstly, the Corcovado Gulf is known for active fishing activities, including artisanal and industrial fisheries. The commercial fishing of hake and spider crab is carried out using large fishing vessels with metallic superstructures and hulls, making their signature on SAR images easily distinguishable compared to smaller or wooden boats. Secondly, considering the limited maritime traffic in the area, except for the passenger lanes connecting Quellón to Guaitecas and Port Raul Marin Balmaceda, we can reasonably assume that the model's detections are primarily associated with fishing activity, eliminating the need for an additional classification model to differentiate between fishing and non-fishing vessels—which development was beyond the scope of this project. This allows us to extrapolate the detections to fishing vessels and qualitatively showcase the application of the model through a case study focused on fisheries. Lastly, the Corcovado region benefits from wide Sentinel 1 coverage, providing multiple complete and partial images of the study area on a monthly basis.\n",
        "\n",
        "The area of interest (AOI) encompasses 6615.83 km2 of sea and coastline at the Corcovado Gulf's entrance. The area is situated between two administrative fishing regions, the X Region of Los Lagos and the XI Region of Aysén, as designated by the Chilean National Service for Fishing and Aquaculture. It also includes a 1019 km2 protected area, the Tictoc-Golfo Corcovado Marine Park, established in 2022 and located northeast of our AOI.\n",
        "\n",
        "\n",
        "Most of the fishing efforts in the AOI are directed towards nine benthic species, including clams, mussels, sea urchins, seaweeds, and crabs from the genus Cancer (Molinet et al. 2011). This activity is primarily carried out by boats ranging from 7 to 15 meters in length, with most of them exceeding the resolution requirements for their detection. However, the area also involves the fisheries of the southern hake (Merluccius australis), and southern king crab (Lithodes santolla), both from artisanal fishing boats with lengths up to 18 m (Molinet et al. 2020)— above SAR’s resolution—, and industrial fishing vessels (Kitts et al. 2020; Molinet et al. 2019). These vessels, and the fishing carriers assisting artisanal vessels in transhipping operations, are the potential targets of the detection model.\n",
        "\n",
        "\n",
        "## Vessel detections\n"
      ],
      "id": "a1f92ef2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the shapefile\n",
        "coastline_path = '../shapefiles/corcovado_coastline/corcovado_coastline.shp'\n",
        "vessels_path = '../shapefiles/baseM/combined_baseM/combined_baseM.shp'\n",
        "aoi_path = '../regions_of_interest/corcovadogulf.geojson'\n",
        "coastline = gpd.read_file(coastline_path)\n",
        "vessels = gpd.read_file(vessels_path)\n",
        "aoi = gpd.read_file(aoi_path)\n",
        "\n",
        "# Set the CRS\n",
        "coastline.crs = 'EPSG:4326' \n",
        "vessels.crs = 'EPSG:4326' \n",
        "aoi.crs = 'EPSG:4326' "
      ],
      "id": "5f00c15f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each vessel detected was assigned its detection score from the model and recorded with the corresponding date and time of the associated SAR image. Detections with scores below 0.6 were removed from the dataset to exclude potential false positives. \n"
      ],
      "id": "a93c9694"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert 'date' column to datetime type\n",
        "vessels['date'] = pd.to_datetime(vessels['date'])\n",
        "# Extract the year and add it as a new column\n",
        "vessels['year'] = vessels['date'].dt.year\n",
        "# Filter by score value\n",
        "filtered_vessels = vessels[vessels['score'] > 0.6]\n",
        "\n",
        "# Create a Folium map centered on the centroid of the vessels GeoDataFrame\n",
        "center_lat = aoi.centroid.y.mean()\n",
        "center_lon = aoi.centroid.x.mean()\n",
        "map = folium.Map(location=[center_lat, center_lon], zoom_start=9,tiles=None)\n",
        "\n",
        "# Add ESRI Ocean Base map\n",
        "esri_ocean = folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri',\n",
        "    name='Esri Ocean',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ")\n",
        "esri_ocean.add_to(map)\n",
        "\n",
        "# Create the coastline feature group\n",
        "coastline_feature_group = folium.FeatureGroup(name='Coastline')\n",
        "\n",
        "# Style function for coastline\n",
        "def coastline_style(feature):\n",
        "    return {'fillColor': '#808080', 'color': '#FFFFFF', 'weight': 0.5}\n",
        "\n",
        "# Iterate over the rows of the GeoDataFrame representing the coastline and add the polygon to the map\n",
        "for index, row in coastline.iterrows():\n",
        "    folium.GeoJson(row['geometry'], style_function=coastline_style).add_to(coastline_feature_group)\n",
        "\n",
        "# Add the coastline feature group to the map\n",
        "map.add_child(coastline_feature_group)\n",
        "\n",
        "# Style function for AOI\n",
        "def aoi_style(feature):\n",
        "    return {'fillOpacity': 0, 'color': '#000000', 'weight': 0.5, 'dashArray': '5, 5'}\n",
        "\n",
        "# Add AOI polygons\n",
        "aoi_feature_group = folium.FeatureGroup(name='Area of Interest')\n",
        "for index, row in aoi.iterrows():\n",
        "    folium.GeoJson(row['geometry'], style_function=aoi_style).add_to(aoi_feature_group)\n",
        "map.add_child(aoi_feature_group)\n",
        "\n",
        "# Sort the unique years\n",
        "unique_years = np.sort(filtered_vessels['year'].unique())\n",
        "\n",
        "# Create a colormap for the different years\n",
        "colors = cm.Reds(np.linspace(0.5, 1, len(unique_years)))\n",
        "\n",
        "# Create a feature group for each year\n",
        "for year, color in zip(unique_years, colors):\n",
        "    year_vessels = filtered_vessels[filtered_vessels['year'] == year]\n",
        "    year_feature_group = folium.FeatureGroup(name=str(year))\n",
        "\n",
        "    # Convert RGB color to hex\n",
        "    color = cm.colors.rgb2hex(color)\n",
        "\n",
        "    # Iterate over the rows of the GeoDataFrame and add markers for each point\n",
        "    for index, row in year_vessels.iterrows():\n",
        "        lat, lon = row['geometry'].y, row['geometry'].x\n",
        "        folium.CircleMarker(location=[lat, lon], radius=2, color='transparent', fill=True, fill_color=color, fill_opacity=0.6,\n",
        "                            popup=f\"Year: {year}\").add_to(year_feature_group)\n",
        "\n",
        "    # Add the year feature group to the map\n",
        "    map.add_child(year_feature_group)\n",
        "\n",
        "# Add layer control to the map (this will add the layer selection control to the map)\n",
        "map.add_child(folium.LayerControl())\n",
        "\n",
        "# Display the map\n",
        "map"
      ],
      "id": "5efd5683",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "Additionally, objects erroneously detected near the shoreline were excluded by clipping them out of a coast shapefile layer obtained from earthworks.stanford.edu. Furthermore, an exclusion buffer of 2km from the coastline was applied to include only vessels operating in open waters, where the fishing activities of interest concentrate. \n"
      ],
      "id": "d5b3ca1b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply buffer to geometries\n",
        "buffer_distance = 0.02  # Buffer distance in (degrees) the unit of the shapefile's coordinate reference system\n",
        "buffered_coastline = coastline.buffer(buffer_distance)\n",
        "buffered_coastline = gpd.GeoDataFrame(geometry=buffered_coastline)\n",
        "# Clip the buffered coastline using the aoi\n",
        "clipped_coastline = gpd.overlay(buffered_coastline, aoi, how='intersection')\n",
        "# Perform the spatial operation to select non-intersecting points\n",
        "non_intersecting_vessels = filtered_vessels[~filtered_vessels.intersects(buffered_coastline.geometry.iloc[0])]\n",
        "\n",
        "# Create a Folium map centered on the centroid of the vessels GeoDataFrame\n",
        "center_lat = aoi.centroid.y.mean()\n",
        "center_lon = aoi.centroid.x.mean()\n",
        "map = folium.Map(location=[center_lat, center_lon], zoom_start=9,tiles=None)\n",
        "\n",
        "# Add ESRI Ocean Base map\n",
        "esri_ocean = folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri',\n",
        "    name='Esri Ocean',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ")\n",
        "esri_ocean.add_to(map)\n",
        "\n",
        "# Create the coastline feature group\n",
        "coastline_feature_group = folium.FeatureGroup(name='Coastline')\n",
        "\n",
        "# Style function for coastline\n",
        "def coastline_style(feature):\n",
        "    return {'fillColor': '#808080', 'color': '#FFFFFF', 'weight': 0.5}\n",
        "\n",
        "# Iterate over the rows of the GeoDataFrame representing the coastline and add the polygon to the map\n",
        "for index, row in coastline.iterrows():\n",
        "    folium.GeoJson(row['geometry'], style_function=coastline_style).add_to(coastline_feature_group)\n",
        "\n",
        "# Add the coastline feature group to the map\n",
        "map.add_child(coastline_feature_group)\n",
        "\n",
        "## Add buffer zone\n",
        "buffer_feature_group = folium.FeatureGroup(name='Buffer')\n",
        "\n",
        "def buffer_style(feature):\n",
        "    return {'fillColor': '#808080', 'color': '#FFFFFF', 'weight': 0.5}\n",
        "\n",
        "for index, row in clipped_coastline.iterrows():\n",
        "    folium.GeoJson(row['geometry'], style_function=buffer_style).add_to(buffer_feature_group)\n",
        "\n",
        "map.add_child(buffer_feature_group)\n",
        "\n",
        "# Style function for AOI\n",
        "def aoi_style(feature):\n",
        "    return {'fillOpacity': 0, 'color': '#000000', 'weight': 0.5, 'dashArray': '5, 5'}\n",
        "\n",
        "# Add AOI polygons\n",
        "aoi_feature_group = folium.FeatureGroup(name='Area of Interest')\n",
        "for index, row in aoi.iterrows():\n",
        "    folium.GeoJson(row['geometry'], style_function=aoi_style).add_to(aoi_feature_group)\n",
        "map.add_child(aoi_feature_group)\n",
        "\n",
        "## Sort the unique years\n",
        "unique_years = np.sort(non_intersecting_vessels['year'].unique())\n",
        "\n",
        "# Create a colormap for the different years\n",
        "colors = cm.Reds(np.linspace(0.5, 1, len(unique_years)))\n",
        "\n",
        "# Create a feature group for each year\n",
        "for year, color in zip(unique_years, colors):\n",
        "    year_vessels = non_intersecting_vessels[non_intersecting_vessels['year'] == year]\n",
        "    year_feature_group = folium.FeatureGroup(name=str(year))\n",
        "\n",
        "    # Convert RGB color to hex\n",
        "    color = cm.colors.rgb2hex(color)\n",
        "\n",
        "    # Iterate over the rows of the GeoDataFrame and add markers for each point\n",
        "    for index, row in year_vessels.iterrows():\n",
        "        lat, lon = row['geometry'].y, row['geometry'].x\n",
        "        folium.CircleMarker(location=[lat, lon], radius=2, color='transparent', fill=True, fill_color=color, fill_opacity=0.6,\n",
        "                            popup=f\"Year: {year}\").add_to(year_feature_group)\n",
        "\n",
        "    # Add the year feature group to the map\n",
        "    map.add_child(year_feature_group)\n",
        "\n",
        "# Add layer control to the map (this will add the layer selection control to the map)\n",
        "map.add_child(folium.LayerControl())\n",
        "\n",
        "# Display the map\n",
        "map"
      ],
      "id": "bc1776ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "After that preprocessing, a total of 365 vessels were identified and selected for the analysis, with most detections occurring during the initial years of the specified timeframe \n",
        "\n",
        "\n",
        "## Spatial information\n",
        "\n",
        "To assess the spatial distribution of the vessels, we generated a static heatmap that combines observations from all five years. Additionally, we created a dynamic heatmap that displays the presence of vessels on a yearly basis.\n",
        "\n",
        "### Heat maps\n"
      ],
      "id": "f5d7f1a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a Folium map centered on the centroid of the vessels GeoDataFrame\n",
        "center_lat = aoi.centroid.y\n",
        "center_lon = aoi.centroid.x\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=9)\n",
        "\n",
        "# Create a new DataFrame with only latitude and longitude columns\n",
        "df_vessels = pd.DataFrame({\n",
        "    'Latitude': non_intersecting_vessels.geometry.y,\n",
        "    'Longitude': non_intersecting_vessels.geometry.x,\n",
        "    'Date': non_intersecting_vessels['date']\n",
        "})\n",
        "\n",
        "# Ensure you're handing it floats\n",
        "df_vessels['Latitude'] = df_vessels['Latitude'].astype(float)\n",
        "df_vessels['Longitude'] = df_vessels['Longitude'].astype(float)\n",
        "\n",
        "# Filter the DF for rows, then columns, then remove NaNs\n",
        "df_vessels = df_vessels[['Latitude', 'Longitude']]\n",
        "df_vessels = df_vessels.dropna(axis=0, subset=['Latitude','Longitude'])\n",
        "\n",
        "# List comprehension to make out list of lists\n",
        "df_vessels = [[row['Latitude'],row['Longitude']] for index, row in df_vessels.iterrows()]\n",
        "\n",
        "# Plot it on the map\n",
        "HeatMap(df_vessels, radius =15).add_to(m)\n",
        "\n",
        "\n",
        "tile = folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri',\n",
        "    name='Esri Satellite',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ").add_to(m)\n",
        "\n",
        "\n",
        "# Display the map\n",
        "m"
      ],
      "id": "53633390",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a new DataFrame with only latitude and longitude columns\n",
        "df_vessels_t = pd.DataFrame({\n",
        "    'Latitude': non_intersecting_vessels.geometry.y,\n",
        "    'Longitude': non_intersecting_vessels.geometry.x,\n",
        "    'Date': non_intersecting_vessels['date']\n",
        "})\n",
        "\n",
        "df_vessels_t['year'] = pd.DatetimeIndex(df_vessels_t['Date']).year\n",
        "\n",
        "index_list = df_vessels_t['year'].astype(str)\n",
        "index_list = index_list.unique().tolist()\n",
        "\n",
        "weight_list = []\n",
        "df_vessels_t['count'] = 1\n",
        "for x in df_vessels_t['year'].sort_values().unique():\n",
        "  weight_list.append(df_vessels_t.loc[df_vessels_t['year'] == x,\n",
        "                                      ['Latitude', 'Longitude','count']].groupby(['Latitude', 'Longitude'])\n",
        "                                      .sum().reset_index().values.tolist())\n",
        "\n",
        "from folium.plugins.heat_map_withtime import HeatMapWithTime\n",
        "# Create a Folium map centered on the centroid of the vessels GeoDataFrame\n",
        "center_lat = aoi.centroid.y\n",
        "center_lon = aoi.centroid.x\n",
        "m = folium.Map(location=[center_lat, center_lon], control_scale=True, zoom_start=9)\n",
        "\n",
        "HeatMapWithTime(weight_list, radius =30, index= index_list,\n",
        "                gradient={0.1: 'blue',0.25:\"green\",0.5:'yellow',0.75:'orange',1:'red'},\n",
        "                auto_play=True, min_opacity=0.1, max_opacity=0.8,blur=1,\n",
        "                use_local_extrema =True, position = \"topright\").add_to(m)\n",
        "\n",
        "\n",
        "tile = folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri',\n",
        "    name='Esri Satellite',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ").add_to(m)\n",
        "\n",
        "m"
      ],
      "id": "4e08aa2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "Attending to the previous maps, we can see that all fishing-related activities, including navigation, fishing, and transhipping, are predominantly concentrated in the southern region of our AOI, particularly in the adjacent waters of Guaitecas. Additionally, there is a noticeable absence of any activity on the east-northeast side, precisely where the Tictoc-Golfo Corcovado Marine Park is located. \n",
        "\n",
        "### Density maps\n",
        "\n",
        "To gain insights into the number of vessels associated with a particular region during each time period, we constructed a density map using a 5x5km grid. This map allows us to visualize the concentration of vessels within specific areas for the entire period and also visualize the changes over time.\n"
      ],
      "id": "4513d543"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the GeoJSON file containing your point data\n",
        "points = non_intersecting_vessels\n",
        "\n",
        "# Define the grid cell size\n",
        "cell_size = 0.05  # Adjust this value according to your requirements\n",
        "\n",
        "# Determine the extent of the point data\n",
        "xmin, ymin, xmax, ymax = aoi.total_bounds\n",
        "\n",
        "# Create a list to store grid cells\n",
        "grid_cells = []\n",
        "\n",
        "# Generate the grid cells\n",
        "x_left = xmin\n",
        "while x_left < xmax:\n",
        "    x_right = x_left + cell_size\n",
        "    y_bottom = ymin\n",
        "    while y_bottom < ymax:\n",
        "        y_top = y_bottom + cell_size\n",
        "        polygon = Polygon([(x_left, y_bottom), (x_right, y_bottom),\n",
        "                           (x_right, y_top), (x_left, y_top)])\n",
        "        grid_cells.append(polygon)\n",
        "        y_bottom += cell_size\n",
        "    x_left += cell_size\n",
        "\n",
        "# Create a GeoDataFrame for the grid cells\n",
        "grid = gpd.GeoDataFrame({'geometry': grid_cells}, crs='EPSG:4326')\n",
        "\n",
        "# Perform the spatial join\n",
        "join = gpd.sjoin(grid, points, op='contains')\n",
        "\n",
        "# Count the number of points in each cell\n",
        "point_counts = join.groupby(join.index).size()\n",
        "\n",
        "# Add the point counts to the grid\n",
        "grid['point_counts'] = point_counts\n",
        "grid['id'] = grid.index\n",
        "\n",
        "# Filter out grid cells with NaN values\n",
        "filtered_grid = grid.dropna(subset=['point_counts'])\n",
        "\n",
        "# Sum all the values in the 'point_counts' column\n",
        "total_sum = filtered_grid['point_counts'].sum()\n",
        "\n",
        "\n",
        "# Create a Folium map centered on the centroid of the vessels GeoDataFrame\n",
        "center_lat = aoi.centroid.y\n",
        "center_lon = aoi.centroid.x\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=9)\n",
        "\n",
        "\n",
        "# Create a Folium Choropleth layer based on the 'point_counts' column\n",
        "folium.Choropleth(\n",
        "    filtered_grid,\n",
        "    name='Grid with Counts',\n",
        "    data=filtered_grid,\n",
        "    columns=['id', 'point_counts'],\n",
        "    key_on='feature.id',\n",
        "    fill_color='YlGnBu',\n",
        "    fill_opacity=0.6,\n",
        "    line_opacity=0,\n",
        "    nan_fill_opacity=0,  # Set opacity to 0 for cells with point_counts equal to 0\n",
        "    legend_name='Vessel Counts',\n",
        "    highlight=True\n",
        "\n",
        ").add_to(m)\n",
        "\n",
        "\n",
        "\n",
        "# Add the grid cells as a GeoJson layer to the map\n",
        "folium.GeoJson(filtered_grid,\n",
        "               name='Grid with Counts',\n",
        "               style_function=lambda feature: {\n",
        "                   'fillColor': 'transparent',\n",
        "                   'color': 'transparent',\n",
        "               },\n",
        "               highlight_function=lambda feature: {\n",
        "                   'fillColor': 'white',\n",
        "                   'color': 'black',\n",
        "                   'weight': 0.5,\n",
        "                   'fillOpacity': 0.3,\n",
        "                   'Opacity': 0.3\n",
        "               },\n",
        "               tooltip=folium.features.GeoJsonTooltip(fields=['point_counts'],\n",
        "                                                      aliases=['Vessel Counts'],\n",
        "                                                      labels=True,\n",
        "                                                      sticky=True)\n",
        "               ).add_to(m)\n",
        "\n",
        "\n",
        "\n",
        "tile = folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri',\n",
        "    name='Esri Satellite',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ").add_to(m)\n",
        "\n",
        "\n",
        "# Display the map\n",
        "\n",
        "m"
      ],
      "id": "505e4149",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the GeoJSON file containing your point data\n",
        "points = non_intersecting_vessels\n",
        "\n",
        "# Convert the date column to datetime format\n",
        "points['date'] = pd.to_datetime(points['date'])\n",
        "\n",
        "# Define the grid cell size\n",
        "cell_size = 0.05  # Adjust this value according to your requirements\n",
        "\n",
        "# Determine the extent of the point data\n",
        "xmin, ymin, xmax, ymax = aoi.total_bounds\n",
        "\n",
        "# Create a list to store grid cells\n",
        "grid_cells = []\n",
        "\n",
        "# Generate the grid cells\n",
        "x_left = xmin\n",
        "while x_left < xmax:\n",
        "    x_right = x_left + cell_size\n",
        "    y_bottom = ymin\n",
        "    while y_bottom < ymax:\n",
        "        y_top = y_bottom + cell_size\n",
        "        polygon = Polygon([(x_left, y_bottom), (x_right, y_bottom),\n",
        "                           (x_right, y_top), (x_left, y_top)])\n",
        "        grid_cells.append(polygon)\n",
        "        y_bottom += cell_size\n",
        "    x_left += cell_size\n",
        "\n",
        "# Create a GeoDataFrame for the grid cells\n",
        "grid = gpd.GeoDataFrame({'geometry': grid_cells}, crs='EPSG:4326')\n",
        "\n",
        "# Perform the spatial join\n",
        "join = gpd.sjoin(grid, points, op='contains')\n",
        "\n",
        "# Extract month and year from the date column\n",
        "join['year'] = join['date'].dt.to_period('Y')\n",
        "\n",
        "# Count the number of points in each cell by month and year\n",
        "point_counts = join.groupby([join.index, 'year']).size().reset_index(name='count')\n",
        "\n",
        "# Merge the point counts with the grid\n",
        "grid = grid.merge(point_counts, how='left', left_index=True, right_on='level_0')\n",
        "\n",
        "# Fill missing values with 0\n",
        "grid['count'] = grid['count'].fillna(0).astype(int)\n",
        "\n",
        "# Rename columns and remove unnecessary ones\n",
        "grid = grid.rename(columns={'count': 'point_counts', 'level_0': 'id'})[['geometry', 'point_counts', 'id', 'year']]\n",
        "\n",
        "# Rename columns and remove unnecessary ones\n",
        "grid = grid.dropna(subset=['year'])\n",
        "\n",
        "\n",
        "# Define the date transformation function\n",
        "def transform_date(period):\n",
        "    date_string = str(period)\n",
        "    date = datetime.strptime(date_string, '%Y')\n",
        "    next_month = date.replace(day=28) + timedelta(days=4)\n",
        "    last_day = next_month - timedelta(days=next_month.day)\n",
        "    last_day_string = last_day.strftime('%Y-%m-%d')\n",
        "    return last_day_string\n",
        "\n",
        "grid['date'] = grid['year'].apply(lambda x: transform_date(x))\n",
        "\n",
        "# Obtain date values in terms of seconds\n",
        "grid[\"date\"] = pd.to_datetime(grid[\"date\"]).values.astype(float)/ 10 ** 9\n",
        "grid[\"date\"] = grid[\"date\"].astype(int).astype(str)\n",
        "\n",
        "# Find the maximum value in the 'point_counts' column\n",
        "max_value = grid['point_counts'].max()\n",
        "\n",
        "# Create an empty dataframe for all combinations of 'id' and 'date'\n",
        "all_combinations = pd.MultiIndex.from_product([grid['id'].unique(), grid['date'].unique()], names=['id', 'date'])\n",
        "\n",
        "# Create a new dataframe with all combinations\n",
        "full_grid = pd.DataFrame(index=all_combinations).reset_index()\n",
        "\n",
        "# Merge full_grid with grid\n",
        "grid = pd.merge(full_grid, grid, on=['id', 'date'], how='left')\n",
        "\n",
        "# Fill missing point_counts with 0\n",
        "grid['point_counts'] = grid['point_counts'].fillna(0).astype(int)\n",
        "\n",
        "# map values in tot_counts to appropriate hex color values\n",
        "min_color, max_color = min(grid[\"point_counts\"]), max(grid[\"point_counts\"])\n",
        "\n",
        "# Define the colormap\n",
        "\n",
        "# Define the color mapper function\n",
        "def color_mapper(count):\n",
        "    if count == 0:\n",
        "        return None\n",
        "    else:\n",
        "        return cmap(count)\n",
        "\n",
        "\n",
        "cmap = linear.YlGnBu_04.scale(min_color, max_color).to_step(max_value)\n",
        "grid[\"color\"] = grid[\"point_counts\"].map(color_mapper)\n",
        "\n",
        "# create a json object with all keys and values--- keys: country index string, values {'color': X , 'opacity': Y}\n",
        "style_dict = {}\n",
        "\n",
        "cell_values = grid[\"id\"].unique()\n",
        "\n",
        "for idx in range(len(cell_values)):\n",
        "    inner_dict = {}\n",
        "    id = cell_values[idx]\n",
        "    rows = grid[grid[\"id\"]== id]\n",
        "    for _, row in rows.iterrows():\n",
        "        color = row[\"color\"]\n",
        "        opacity = 0 if row['point_counts'] == 0 else 0.6  # adjust opacity here\n",
        "        inner_dict[row[\"date\"]] = {\"color\": color, \"opacity\": opacity }\n",
        "    style_dict[idx] = inner_dict\n",
        "\n",
        "\n",
        "feature_dict = {}\n",
        "\n",
        "grid = gpd.GeoDataFrame(grid)\n",
        "\n",
        "geometries = grid[[\"geometry\"]]\n",
        "geo_geometries = gpd.GeoDataFrame(geometries)\n",
        "geo_geometries = geo_geometries.drop_duplicates().reset_index()\n",
        "\n",
        "# Create a Folium map centered at the mean coordinates of the grid\n",
        "center = [grid['geometry'].centroid.y.mean(), grid['geometry'].centroid.x.mean()]\n",
        "slider_map = folium.Map(location=center, zoom_start=9)\n",
        "\n",
        "TimeSliderChoropleth(\n",
        "    name=\"Time slider\",\n",
        "    data=geo_geometries.to_json(),\n",
        "    styledict=style_dict\n",
        ").add_to(slider_map)\n",
        "\n",
        "\n",
        "\n",
        "tile = folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri',\n",
        "    name='Esri Satellite',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ").add_to(slider_map)\n",
        "\n",
        "cmap.add_to(slider_map)\n",
        "cmap.caption = \"Vessels\"\n",
        "\n",
        "slider_map"
      ],
      "id": "41cdf625",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "Despite the limited scope of this analysis, some of its findings could potentially be used for describing the local fisheries. For instance, the spatial pattern detected could be attributed to the location of the primary fishing grounds, which would be situated north of Guaitecas and east of the Queitao islands in the central region of the AOI. This distribution at least highlights areas where fishing activity is not predominant and from which fishery enforcement efforts could be redirected towards higher vessel density areas.\n",
        "\n",
        "Additionally, the absence of vessel presence within the waters inside the Marine Park is noteworthy. This observation sheds light on the rationale behind designating that specific area as protected in 2022. It is possible that the area's lower interest and reduced conflict among stakeholders facilitated or influenced its selection for protection.\n",
        "\n",
        "\n",
        "## Temporal series\n",
        "\n",
        "Regarding to the temporal distribution of the detections, the following figure illustrates the number of selected vessels per month. Consistent with the values in the following table, the graph shows an overall downward trend in the number of detected vessels over the years. However, the variations in vessel counts can be explained by the changes in SAR images availability and area covered rather than actuall changes in vessel precense. \n"
      ],
      "id": "7bfb78d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vessels_of_interest = non_intersecting_vessels\n",
        "vessels_of_interest['date'] = pd.to_datetime(vessels_of_interest['date'])\n",
        "\n",
        "# Create a new column combining year and month\n",
        "vessels_of_interest['year_month'] = vessels_of_interest['date'].dt.to_period('M')\n",
        "\n",
        "# Group by the combined year and month column, counting the observations\n",
        "vessels_monthyear = vessels_of_interest.groupby('year_month').size().reset_index(name='vessels')\n",
        "\n",
        "# Convert year_month to Timestamp objects\n",
        "vessels_monthyear['year_month'] = pd.to_datetime(vessels_monthyear['year_month'].astype(str))\n",
        "\n",
        "# Normalize 'vessels' values for color mapping\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "vessel_norm = min_max_scaler.fit_transform(vessels_monthyear[['vessels']])\n",
        "\n",
        "# Create a blue color scale with color starting from the midpoint\n",
        "colorscale = [[0, 'rgb(158, 202, 225)'], [1, 'rgb(8, 48, 107)']]\n",
        "\n",
        "data = go.Bar(\n",
        "    x=vessels_monthyear['year_month'],\n",
        "    y=vessels_monthyear['vessels'],\n",
        "    marker=dict(\n",
        "        color=vessel_norm.ravel(),\n",
        "        colorscale=colorscale\n",
        "    ),\n",
        "    name=\"\",\n",
        "    hovertemplate =\n",
        "    '<b>Date</b>: %{x|%B %Y}'+\n",
        "    '<br><b>Vessels</b>: %{y}<br>',\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    )\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Detected vessels per Month',\n",
        "    xaxis=dict(title='', tickangle=45),\n",
        "    yaxis=dict(title='Number of vessels'),\n",
        "    paper_bgcolor='rgba(0,0,0,0)',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(data=[data], layout=layout)\n",
        "\n",
        "fig.show()"
      ],
      "id": "9f95721d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To address this, and to derive meaningful conclusions from the temporal series, we can normalize the number of vessels based on the corresponding area covered in the images processed for each month.\n"
      ],
      "id": "05c2b895"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_details_path = '/Users/polcarbo/Documents/Documents/2023/UOC/PEC/PEC4/SSDD_pcarbomestre3.0/case_study/image_details.xlsx'\n",
        "image_details = pd.read_excel(image_details_path)\n",
        "\n",
        "# Convert date column to datetime\n",
        "image_details['date'] = pd.to_datetime(image_details['date'])\n",
        "# Create new column for year_month\n",
        "image_details['year_month'] = image_details['date'].dt.to_period('M')\n",
        "# Group by the combined year and month column, aggregating the area\n",
        "image_details_monthyear = image_details.groupby('year_month')['area'].sum().reset_index()\n",
        "# Convert year_month to Timestamp objects\n",
        "image_details_monthyear['year_month'] = image_details_monthyear['year_month'].dt.to_timestamp()\n",
        "# Merge the two dataframes on 'year_month'\n",
        "combined_df = pd.merge(image_details_monthyear, vessels_monthyear, on='year_month')\n",
        "# Convert area from m^2 to km^2\n",
        "combined_df['area_km2'] = combined_df['area'] / 1e6\n",
        "# Create new column for vessels per km^2\n",
        "combined_df['vessels_per_km2'] = combined_df['vessels'] / combined_df['area_km2']\n",
        "# Normalize vessels_per_km2\n",
        "combined_df['vessels_per_km2_normalized'] = (combined_df['vessels_per_km2'] - combined_df['vessels_per_km2'].min()) / (combined_df['vessels_per_km2'].max() - combined_df['vessels_per_km2'].min())\n",
        "\n",
        "# Normalize 'vessels' values for color mapping\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "vessel_norm = min_max_scaler.fit_transform(combined_df[['vessels']])\n",
        "\n",
        "# Create a blue color scale with color starting from the midpoint\n",
        "colorscale = [[0, 'rgb(158, 202, 225)'], [1, 'rgb(8, 48, 107)']]\n",
        "\n",
        "data = go.Bar(\n",
        "    x=combined_df['year_month'],\n",
        "    y=combined_df['vessels_per_km2'],\n",
        "    marker=dict(\n",
        "        color=vessel_norm.ravel(),\n",
        "        colorscale=colorscale\n",
        "    ),\n",
        "    name=\"\",\n",
        "    hovertemplate =\n",
        "    '<b>Date</b>: %{x|%B %Y}'+\n",
        "    '<br><b>Vessels</b>: %{y}<br>',\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    )\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Detected vessels per Month',\n",
        "    xaxis=dict(title='', tickangle=45),\n",
        "    yaxis=dict(title='Number of vessels/km2'),\n",
        "    paper_bgcolor='rgba(0,0,0,0)',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(data=[data], layout=layout)\n",
        "\n",
        "fig.show()"
      ],
      "id": "555c941f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The normalized time series, reveals that the previous downward trend is no longer evident. In this case, there isn't a noticeable pattern across the years. However, there are some anomalies in the number of detections, such as a significant increase at the end of 2019. It would be worthwhile to investigate whether this could be linked to a specific event related to fishing activities in the region, such as changes in fishing regulations like quota increases or an abnormality in the stock's growth due to ecological processes.\n",
        "\n",
        "### Seasonal distribution\n",
        "\n",
        "To further explore the temporal dimension of the data, we can examine if there is a seasonal factor. In the next figure it is evident that most detections occurred at the years' ends, particularly in October, November, and December. Additionally, when evaluated by season, fall and winter accounted for the highest number of detections. This pattern could respond to the start of the fishing season. \n"
      ],
      "id": "e48fac96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "combined_df['year_month'] = pd.to_datetime(combined_df['year_month'])\n",
        "# create a new column for the month\n",
        "combined_df['month'] = combined_df['year_month'].dt.month\n",
        "# group by month and calculate sum for each group\n",
        "grouped_df = combined_df.groupby('month')[['area', 'vessels']].sum().reset_index()\n",
        "\n",
        "# Group by the combined year and month column, aggregating the area\n",
        "grouped_df_month = grouped_df\n",
        "# Convert area from m^2 to km^2\n",
        "grouped_df_month['area_km2'] = grouped_df_month['area'] / 1e6\n",
        "# Create new column for vessels per km^2\n",
        "grouped_df_month['vessels_per_km2'] = grouped_df_month['vessels'] / grouped_df_month['area_km2']\n",
        "# Normalize vessels_per_km2\n",
        "grouped_df_month['vessels_per_km2_normalized'] = (grouped_df_month['vessels_per_km2'] - grouped_df_month['vessels_per_km2'].min()) / (grouped_df_month['vessels_per_km2'].max() - grouped_df_month['vessels_per_km2'].min())\n",
        "\n",
        "months = {12: 'December', 1: 'January', 2: 'February',\n",
        "           3: 'March', 4: 'April', 5: 'May',\n",
        "           6: 'June', 7: 'July', 8: 'August',\n",
        "           9: 'September', 10: 'October', 11: 'November'}\n",
        "\n",
        "grouped_df_month['month'] = grouped_df_month['month'].map(months)\n",
        "\n",
        "# Normalize 'vessels' values for color mapping\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "vessel_norm = min_max_scaler.fit_transform(grouped_df_month[['vessels']])\n",
        "\n",
        "# Create a blue color scale with color starting from the midpoint\n",
        "colorscale = [[0, 'rgb(158, 202, 225)'], [1, 'rgb(8, 48, 107)']]\n",
        "\n",
        "data = go.Bar(\n",
        "    x=grouped_df_month['month'],\n",
        "    y=grouped_df_month['vessels_per_km2'],\n",
        "    marker=dict(\n",
        "        color=vessel_norm.ravel(),\n",
        "        colorscale=colorscale\n",
        "    ),\n",
        "    name=\"\",\n",
        "    hovertemplate =\n",
        "    '<br><b>Vessels/km2</b>: %{y}<br>',\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    )\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Detected vessels per Month',\n",
        "    xaxis=dict(title='', tickangle=45),\n",
        "    yaxis=dict(title='Number of vessels/km2',tickformat=\".4f\"),\n",
        "    paper_bgcolor='rgba(0,0,0,0)',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(data=[data], layout=layout)\n",
        "\n",
        "fig.show()"
      ],
      "id": "d8a12e1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "combined_df['year_month'] = pd.to_datetime(combined_df['year_month'])\n",
        "# create a new column for the month\n",
        "combined_df['month'] = combined_df['year_month'].dt.month\n",
        "# group by month and calculate sum for each group\n",
        "grouped_df = combined_df.groupby('month')[['area', 'vessels']].sum().reset_index()\n",
        "\n",
        "seasons = {12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
        "           3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
        "           6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
        "           9: 'Autumn', 10: 'Autumn', 11: 'Autumn'}\n",
        "\n",
        "grouped_df['season'] = grouped_df['month'].map(seasons)\n",
        "\n",
        "# Group by season and calculate sum for 'area' and 'vessels'\n",
        "grouped_by_season_df = grouped_df.groupby('season')[['area', 'vessels']].sum().reset_index()\n",
        "\n",
        "# Group by the combined year and month column, aggregating the area\n",
        "grouped_df_season = grouped_by_season_df\n",
        "# Convert area from m^2 to km^2\n",
        "grouped_df_season['area_km2'] = grouped_df_season['area'] / 1e6\n",
        "# Create new column for vessels per km^2\n",
        "grouped_df_season['vessels_per_km2'] = grouped_df_season['vessels'] / grouped_df_season['area_km2']\n",
        "# Normalize vessels_per_km2\n",
        "grouped_df_season['vessels_per_km2_normalized'] = (grouped_df_season['vessels_per_km2'] - grouped_df_season['vessels_per_km2'].min()) / (grouped_df_season['vessels_per_km2'].max() - grouped_df_season['vessels_per_km2'].min())\n",
        "\n",
        "# Normalize 'vessels' values for color mapping\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "vessel_norm = min_max_scaler.fit_transform(grouped_df_season[['vessels']])\n",
        "\n",
        "# Create a blue color scale with color starting from the midpoint\n",
        "colorscale = [[0, 'rgb(158, 202, 225)'], [1, 'rgb(8, 48, 107)']]\n",
        "\n",
        "data = go.Bar(\n",
        "    x=grouped_df_season['season'],\n",
        "    y=grouped_df_season['vessels_per_km2'],\n",
        "    marker=dict(\n",
        "        color=vessel_norm.ravel(),\n",
        "        colorscale=colorscale\n",
        "    ),\n",
        "    name=\"\",\n",
        "    hovertemplate =\n",
        "    '<br><b>Vessels/km2</b>: %{y}<br>',\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    )\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Detected vessels per Month',\n",
        "    xaxis=dict(title='', tickangle=45),\n",
        "    yaxis=dict(title='Number of vessels/km2',tickformat=\".5f\"),\n",
        "    paper_bgcolor='rgba(0,0,0,0)',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(data=[data], layout=layout)\n",
        "\n",
        "fig.show()"
      ],
      "id": "7b807ecf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis limitations\n",
        "\n",
        "It is important to emphasize that this case study does not attempt to analyze a fishery science case thoroughly. Instead, it aims to showcase the practical application of vessel detection models in fisheries management. Its main objective is to comment on the derived data outputs from these detections and establish correlations with existing scientific work that has successfully implemented this technology for fisheries management. \n",
        "\n",
        "In this particular case, it is important to point out that the data cannot be directly extrapolated for fishing purposes. To achieve this, a classification model is necessary to accurately distinguish between fishing vessels and other types of boats. This differentiation is crucial as it enables the correlation of detections with actual fishing activity. Furthermore, a more comprehensive evaluation of the specific AOI and its fisheries should be conducted. This would allow for the formulation of hypotheses regarding the detections and their potential linkage to regional fishing trends. Additionally, it is essential to incorporate data from other sources to support the observations derived from the detection model. A more robust and comprehensive analysis could be achieved by combining traditional observations that define the regional fisheries with our detections.\n",
        "\n",
        "While the analysis in this case study had a limited extent, focusing on data extraction, transformation, and representation, it has also served to reveal certain limitations of this technology, including the temporal resolution of SAR images, its constraint for detecting small vessels, and the need of a reliable classification model."
      ],
      "id": "1c6ba709"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}